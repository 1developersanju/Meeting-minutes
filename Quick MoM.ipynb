{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20012,"status":"ok","timestamp":1674837315451,"user":{"displayName":"AI Anytime","userId":"17552813243112873021"},"user_tz":-330},"id":"oC7YUnRKEeyk","outputId":"49de40c6-6f8d-400f-cba9-a1ed4fef0898"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: openai in ./.venv/lib/python3.10/site-packages (1.14.0)\n","Requirement already satisfied: distro<2,>=1.7.0 in ./.venv/lib/python3.10/site-packages (from openai) (1.9.0)\n","Requirement already satisfied: typing-extensions<5,>=4.7 in ./.venv/lib/python3.10/site-packages (from openai) (4.10.0)\n","Requirement already satisfied: sniffio in ./.venv/lib/python3.10/site-packages (from openai) (1.3.1)\n","Requirement already satisfied: tqdm>4 in ./.venv/lib/python3.10/site-packages (from openai) (4.66.2)\n","Requirement already satisfied: anyio<5,>=3.5.0 in ./.venv/lib/python3.10/site-packages (from openai) (4.3.0)\n","Requirement already satisfied: pydantic<3,>=1.9.0 in ./.venv/lib/python3.10/site-packages (from openai) (2.6.4)\n","Requirement already satisfied: httpx<1,>=0.23.0 in ./.venv/lib/python3.10/site-packages (from openai) (0.27.0)\n","Requirement already satisfied: exceptiongroup>=1.0.2 in ./.venv/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n","Requirement already satisfied: idna>=2.8 in ./.venv/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.6)\n","Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (1.0.4)\n","Requirement already satisfied: certifi in ./.venv/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n","Requirement already satisfied: h11<0.15,>=0.13 in ./.venv/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n","Requirement already satisfied: pydantic-core==2.16.3 in ./.venv/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (2.16.3)\n","Requirement already satisfied: annotated-types>=0.4.0 in ./.venv/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n","\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"]}],"source":["!pip3 install openai"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"1rj2x2-OF7Xp"},"outputs":[],"source":["prompt =\"\"\"\n","Chairman Wormsley (at the proper time and place, after taking the chair and striking the gavel on the table): This meeting of the CTAS County Commission will come to order. Clerk please call the role. (Ensure that a majority of the members are present.)\n","\n","Chairman Wormsley: Each of you has received the agenda. I will entertain a motion that the agenda be approved.\n","\n","Commissioner Brown: So moved.\n","\n","Commissioner Hobbs: Seconded\n","\n","Chairman Wormsley: It has been moved and seconded that the agenda be approved as received by the members. All those in favor signify by saying \"Aye\"?...Opposed by saying \"No\"?...The agenda is approved. You have received a copy of the minutes of the last meeting. Are there any corrections or additions to the meeting?\n","\n","Commissioner McCroskey: Mister Chairman, my name has been omitted from the Special Committee on Indigent Care.\n","\n","Chairman Wormsley: Thank you. If there are no objections, the minutes will be corrected to include the name of Commissioner McCroskey. Will the clerk please make this correction. Any further corrections? Seeing none, without objection the minutes will stand approved as read. (This is sort of a short cut way that is commonly used for approval of minutes and/or the agenda rather than requiring a motion and second.)\n","\n","Chairman Wormsley: Commissioner Adkins, the first item on the agenda is yours.\n","\n","Commissioner Adkins: Mister Chairman, I would like to make a motion to approve the resolution taking money from the Data Processing Reserve Account in the County Clerk's office and moving it to the equipment line to purchase a laptop computer.\n","\n","Commissioner Carmical: I second the motion.\n","\n","Chairman Wormsley: This resolution has a motion and second. Will the clerk please take the vote.\n","\n","Chairman Wormsley: The resolution passes. We will now take up old business. At our last meeting, Commissioner McKee, your motion to sell property near the airport was deferred to this meeting. You are recognized.\n","\n","Commissioner McKee: I move to withdraw that motion.\n","\n","Chairman Wormsley: Thank you so much, thats's really helps. Talk to you next monday.\n","\"\"\""]},{"cell_type":"code","execution_count":38,"metadata":{"id":"_XxRS5MiFPZU"},"outputs":[],"source":["import os\n","import openai\n","\n","openai.api_key = \"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\"\n","response = openai.completions.create(model=\"gpt-3.5-turbo-instruct\",prompt= \"Can you generate the Minute of Meeting in form of tasks like who is the assigner and who is the assignee what is the due date and other discuessed for the below transcript?\\n\"+prompt, temperature=0.7, max_tokens=256, top_p=1,frequency_penalty=0, presence_penalty=0)\n"]},{"cell_type":"code","execution_count":39,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":70},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1674838148927,"user":{"displayName":"AI Anytime","userId":"17552813243112873021"},"user_tz":-330},"id":"smy3kK6oIQNA","outputId":"881465d8-2df0-40e9-aba5-89386bc01aad"},"outputs":[{"data":{"text/plain":["'\\nTask: \\n1. Assigner: Chairman Wormsley\\nAssignee: Clerk\\nDue Date: At the proper time and place\\nDiscussion: Take role call and ensure majority of members are present.\\n\\n2. Assigner: Chairman Wormsley\\nAssignee: Commissioners\\nDue Date: None\\nDiscussion: Each member has received the agenda. Motion to approve the agenda.\\n\\n3. Assigner: Chairman Wormsley\\nAssignee: Clerk\\nDue Date: None\\nDiscussion: Call for a vote to approve the agenda.\\n\\n4. Assigner: Chairman Wormsley\\nAssignee: Commissioners\\nDue Date: None\\nDiscussion: Review and approve minutes of the last meeting. Corrections or additions should be mentioned.\\n\\n5. Assigner: Chairman Wormsley\\nAssignee: Clerk\\nDue Date: None\\nDiscussion: Clerk to make corrections to minutes if needed.\\n\\n6. Assigner: Chairman Wormsley\\nAssignee: Commissioners\\nDue Date: None\\nDiscussion: Approval of minutes without objection.\\n\\n7. Assigner: Chairman Wormsley\\nAssignee: Commissioner Adkins\\nDue Date: None\\nDiscussion: Commissioner Adkins presents motion to approve resolution for purchasing a laptop computer. Discussion and vote to follow.\\n\\n8. Assigner: Chairman Worm'"]},"execution_count":39,"metadata":{},"output_type":"execute_result"}],"source":["generated_text = response.choices[0].text\n","generated_text"]},{"cell_type":"code","execution_count":31,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13676,"status":"ok","timestamp":1674838901983,"user":{"displayName":"AI Anytime","userId":"17552813243112873021"},"user_tz":-330},"id":"qB66GVaVLPsA","outputId":"31f96a86-9153-486c-9d80-9156fd100da8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: openai-whisper in ./.venv/lib/python3.10/site-packages (20231117)\n","Requirement already satisfied: numpy in ./.venv/lib/python3.10/site-packages (from openai-whisper) (1.26.4)\n","Requirement already satisfied: torch in ./.venv/lib/python3.10/site-packages (from openai-whisper) (2.2.1)\n","Requirement already satisfied: numba in ./.venv/lib/python3.10/site-packages (from openai-whisper) (0.59.0)\n","Requirement already satisfied: tiktoken in ./.venv/lib/python3.10/site-packages (from openai-whisper) (0.6.0)\n","Requirement already satisfied: more-itertools in ./.venv/lib/python3.10/site-packages (from openai-whisper) (10.2.0)\n","Requirement already satisfied: tqdm in ./.venv/lib/python3.10/site-packages (from openai-whisper) (4.66.2)\n","Requirement already satisfied: llvmlite<0.43,>=0.42.0dev0 in ./.venv/lib/python3.10/site-packages (from numba->openai-whisper) (0.42.0)\n","Requirement already satisfied: regex>=2022.1.18 in ./.venv/lib/python3.10/site-packages (from tiktoken->openai-whisper) (2023.12.25)\n","Requirement already satisfied: requests>=2.26.0 in ./.venv/lib/python3.10/site-packages (from tiktoken->openai-whisper) (2.31.0)\n","Requirement already satisfied: fsspec in ./.venv/lib/python3.10/site-packages (from torch->openai-whisper) (2024.2.0)\n","Requirement already satisfied: jinja2 in ./.venv/lib/python3.10/site-packages (from torch->openai-whisper) (3.1.3)\n","Requirement already satisfied: networkx in ./.venv/lib/python3.10/site-packages (from torch->openai-whisper) (3.2.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in ./.venv/lib/python3.10/site-packages (from torch->openai-whisper) (4.10.0)\n","Requirement already satisfied: filelock in ./.venv/lib/python3.10/site-packages (from torch->openai-whisper) (3.13.1)\n","Requirement already satisfied: sympy in ./.venv/lib/python3.10/site-packages (from torch->openai-whisper) (1.12)\n","Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.3.2)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.2.1)\n","Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2024.2.2)\n","Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.6)\n","Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.10/site-packages (from jinja2->torch->openai-whisper) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in ./.venv/lib/python3.10/site-packages (from sympy->torch->openai-whisper) (1.3.0)\n","\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"]}],"source":["!pip3 install -U openai-whisper"]},{"cell_type":"code","execution_count":40,"metadata":{"id":"hO12jxDcIY_k"},"outputs":[],"source":["import subprocess\n","import whisper"]},{"cell_type":"code","execution_count":41,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1674840045804,"user":{"displayName":"AI Anytime","userId":"17552813243112873021"},"user_tz":-330},"id":"BSS1odbhL-dB","outputId":"47e731f8-fe58-4eef-fdc0-ac4affa26b58"},"outputs":[{"name":"stderr","output_type":"stream","text":["/bin/sh: ffmpeg: command not found\n"]},{"data":{"text/plain":["CompletedProcess(args='ffmpeg -i \"path/filename\".mp4 \"filename\".mp3', returncode=127)"]},"execution_count":41,"metadata":{},"output_type":"execute_result"}],"source":["import subprocess\n","\n","path = 'interview.mp4'\n","\n","subprocess.run('ffmpeg -i \"path/filename\".mp4 \"filename\".mp3',shell=True)"]},{"cell_type":"code","execution_count":42,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5394,"status":"ok","timestamp":1674840174886,"user":{"displayName":"AI Anytime","userId":"17552813243112873021"},"user_tz":-330},"id":"hxW2qUreQI-m","outputId":"6d5c98e5-afa1-46b3-8e91-c5de716ac801"},"outputs":[{"name":"stdout","output_type":"stream","text":["zsh:1: command not found: ffmpeg\n"]}],"source":["!ffmpeg -i \"interview.mp4\" \"audio_file.mp3\""]},{"cell_type":"code","execution_count":44,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":108105,"status":"ok","timestamp":1674840289142,"user":{"displayName":"AI Anytime","userId":"17552813243112873021"},"user_tz":-330},"id":"ofrKxBK7LxWx","outputId":"27db0684-8972-42d4-8277-7b9f8598240d"},"outputs":[{"name":"stderr","output_type":"stream","text":["/Users/drole/Documents/SIH/MoM/.venv/lib/python3.10/site-packages/whisper/transcribe.py:115: UserWarning: FP16 is not supported on CPU; using FP32 instead\n","  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"]},{"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: 'ffmpeg'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[44], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m whisper\u001b[38;5;241m.\u001b[39mload_model(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbase\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranscribe\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maudio_file.mp3\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n","File \u001b[0;32m~/Documents/SIH/MoM/.venv/lib/python3.10/site-packages/whisper/transcribe.py:122\u001b[0m, in \u001b[0;36mtranscribe\u001b[0;34m(model, audio, verbose, temperature, compression_ratio_threshold, logprob_threshold, no_speech_threshold, condition_on_previous_text, initial_prompt, word_timestamps, prepend_punctuations, append_punctuations, **decode_options)\u001b[0m\n\u001b[1;32m    119\u001b[0m     decode_options[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfp16\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;66;03m# Pad 30-seconds of silence to the input audio, for slicing\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m mel \u001b[38;5;241m=\u001b[39m \u001b[43mlog_mel_spectrogram\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdims\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_mels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mN_SAMPLES\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    123\u001b[0m content_frames \u001b[38;5;241m=\u001b[39m mel\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m N_FRAMES\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m decode_options\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlanguage\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","File \u001b[0;32m~/Documents/SIH/MoM/.venv/lib/python3.10/site-packages/whisper/audio.py:140\u001b[0m, in \u001b[0;36mlog_mel_spectrogram\u001b[0;34m(audio, n_mels, padding, device)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mis_tensor(audio):\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(audio, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m--> 140\u001b[0m         audio \u001b[38;5;241m=\u001b[39m \u001b[43mload_audio\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m     audio \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(audio)\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","File \u001b[0;32m~/Documents/SIH/MoM/.venv/lib/python3.10/site-packages/whisper/audio.py:58\u001b[0m, in \u001b[0;36mload_audio\u001b[0;34m(file, sr)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# fmt: on\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcapture_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mstdout\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CalledProcessError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to load audio: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mdecode()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/subprocess.py:503\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    500\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstdout\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m PIPE\n\u001b[1;32m    501\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstderr\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m PIPE\n\u001b[0;32m--> 503\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpopenargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[1;32m    504\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    505\u001b[0m         stdout, stderr \u001b[38;5;241m=\u001b[39m process\u001b[38;5;241m.\u001b[39mcommunicate(\u001b[38;5;28minput\u001b[39m, timeout\u001b[38;5;241m=\u001b[39mtimeout)\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/subprocess.py:971\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize)\u001b[0m\n\u001b[1;32m    967\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext_mode:\n\u001b[1;32m    968\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mTextIOWrapper(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr,\n\u001b[1;32m    969\u001b[0m                     encoding\u001b[38;5;241m=\u001b[39mencoding, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m--> 971\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreexec_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mpass_fds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshell\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mp2cread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp2cwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mc2pread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc2pwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[43m                        \u001b[49m\u001b[43merrread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mrestore_signals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    978\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mgid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mumask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    979\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstart_new_session\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m    981\u001b[0m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n\u001b[1;32m    982\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdin, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr)):\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/subprocess.py:1863\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, gid, gids, uid, umask, start_new_session)\u001b[0m\n\u001b[1;32m   1861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errno_num \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1862\u001b[0m         err_msg \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mstrerror(errno_num)\n\u001b[0;32m-> 1863\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m child_exception_type(errno_num, err_msg, err_filename)\n\u001b[1;32m   1864\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m child_exception_type(err_msg)\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'ffmpeg'"]}],"source":["model = whisper.load_model(\"base\")\n","result = model.transcribe(\"audio_file.mp3\")\n","print(result[\"text\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D6K1QPXmQ2KP"},"outputs":[],"source":["transcript = result[\"text\"]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":122},"executionInfo":{"elapsed":24,"status":"ok","timestamp":1674840356659,"user":{"displayName":"AI Anytime","userId":"17552813243112873021"},"user_tz":-330},"id":"ysCPR2vwQ6A7","outputId":"ac8d1c22-470a-4b5a-d5c5-d78094392d55"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\" Yeah, I hate the word AI called artificial intelligence. I call it alibaba intelligence. Yeah. Might end up being true, you never know. Um, fairly getting any information out, basically with speech. Yeah, I'm always amazed by the, what you're vision about the technology. I'm not a tech guy. I think I'm all about life. I think AI is going to open a new chapter of the society of the world that people try to understand ourself better, rather than the outside world. And it's so difficult to predict the future. 99.99% of the predictions that human being had in history about the future are wrong. Including that one? Oh, yeah. Only, you know, the zero point, zero zero percent of the prediction are right. They're right because by accident. Yeah, but it's also true that 80% of statistics are false. Yeah. So my meaning is... Cold room. Come on, guys. It was a joke. My name is, I'm happy about the, people worry a lot about this today. Are those people, I called them, called, um, uh, called college smarteners? People like us, street smart. We never scared of that. We, we think it's a great fun and we want to change ourself to embrace it. I don't know, man. That's like famous last words. This is, let me tell you, like you couldn't evolve Silicon circuits. You needed to be a biology to get there. Good. Yeah. Well, let's talk about something fun. What do you think about that? Actually, I'm not interested in a Mars. I just came back from there, so... I'm more interested in the Earth. The things, what's going on happening here? So, why are you so curious about the Mars? Just a one step ago to Mars, but you would never be able to come back. Yeah. Well, that's my view. That's not works though. And, uh, also, also... Don't do it. I hate to go to Himalayas too. I mean, when you climb on the, I think someday I would go there when the elevator's ready. I would go there and look. But, well, that's my view about jobs. Don't worry about it. You will have jobs. Yeah. I, I, I... I, I, I, I think, I think of like technology, like technology and technology awareness. There's like, it's like, if there was like a topological map of technology awareness, it's mostly flat, with a few short buildings and then some very toll spires, very toll spires. And unless you're on that very toll spire, it's not obvious what the topology is. Yeah. I never worry about the things that I cannot solve. I let other people to solve it. If nobody can solve it, just let it be. That's my life. Oh, let's talk about education. I'm quite interested in about education. Computer only have chips. Man have the heart. It's the heart where the wisdom comes from. So, I think that's my view. And don't worry about it. We will change it. Yeah. Okay, let's go. So, I never, in my life, and especially last two years when people talk about AI, say, human, human being will be controlled by machines. I never think about that. I think it's, it's, it's, it's impossible. Right? It's impossible. Because, because human beings, they are different. Machines are invented by human beings. And according to the science, right, humans can never create another animal that is smart and human. Especially when you have so many smart people, it's impossible to make another smart people. I very much disagree with that. Okay. Yeah. That's good. Yeah. Okay. Okay. Yeah. My view is that, um, computer may be clever, but human being are much smarter. Yeah, definitely not. Clever is very academic. So, I told those guys, they are very sad. So, uh, computer will be smarter than human beings because computer can play chess better. Uh, I think you have stupid to compete with that. Don't do that. So, this is, this is, we always do things we are good at. Sure. Okay. Well, what would be an example of something that humans are better than a computer at? And, and then let's see if that happens. Well, humans, computer is only one of the collaborative tools that human created. And computers are a clever, but there will be more tools that human beings will create. It's much clever than computers. That's my view. Okay. Okay. Okay. Okay. Right? In the future, if you want to survive in this world, you have to be the LQ, the Q of love. That's important too. Otherwise, you can survive in that efficient talent. It's time. Yeah. But I agree with love is the answer. Yeah. Many songs about that.\""]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["transcript"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15350,"status":"ok","timestamp":1674840600703,"user":{"displayName":"AI Anytime","userId":"17552813243112873021"},"user_tz":-330},"id":"Z-yqdc2PRiom","outputId":"4aec08b0-bfc6-4270-d129-7b7b71a26613"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: moviepy in /usr/local/lib/python3.8/dist-packages (0.2.3.5)\n","Requirement already satisfied: imageio<3.0,>=2.1.2 in /usr/local/lib/python3.8/dist-packages (from moviepy) (2.9.0)\n","Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.8/dist-packages (from moviepy) (4.64.1)\n","Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.8/dist-packages (from moviepy) (4.4.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from moviepy) (1.21.6)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.8/dist-packages (from imageio<3.0,>=2.1.2->moviepy) (7.1.2)\n"]}],"source":["!pip install moviepy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r8wjTfScRTGF"},"outputs":[],"source":["def audio_to_transcript(audio_file):\n","  "]},{"cell_type":"markdown","metadata":{"id":"rcIEJbV4RJbx"},"source":["## Open AI Function"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nS5JZ__lQQG3"},"outputs":[],"source":["def MoM_generation(prompt):\n","  response = openai.Completion.create(model=\"text-davinci-003\",\n","                                      prompt= \"Can you generate the Minute of Meeting in form of bullet points for the below transcript?\\n\"+prompt, \n","                                      temperature=0.7, \n","                                      max_tokens=256, \n","                                      top_p=1,\n","                                      frequency_penalty=0, \n","                                      presence_penalty=0)\n","  return response['choices'][0]['text']"]},{"cell_type":"markdown","metadata":{"id":"imKn5IzvRNbH"},"source":["## Final output"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uN47DN9bQyWz"},"outputs":[],"source":["result = MoM_generation(transcript)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ffpv9-oSRCQO"},"outputs":[],"source":["import json\n","json_result = json.dumps('{\"result\": '+ result + '}')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":507,"status":"ok","timestamp":1674843576592,"user":{"displayName":"AI Anytime","userId":"17552813243112873021"},"user_tz":-330},"id":"5a8XJrRPb8l_","outputId":"28d3e4dc-1455-488b-fb95-fac0ddc4f536"},"outputs":[{"name":"stdout","output_type":"stream","text":["{\"result\": \n","\n","Minute of Meeting:\n","- Discussion about Artificial Intelligence\n","- AI referred to as 'Alibaba Intelligence'\n","- AI will open up a new chapter of society where people understand themselves better\n","- Predictions about the future are usually wrong\n","- People who are 'college smarteners' and 'street smart' are not scared of AI\n","- Human beings can never create an animal that is smarter than them\n","- Computers are cleverer than humans, but humans will create tools that are even cleverer than computers\n","- To survive in the future, one needs to have the LQ (Love Quotient)}\n"]}],"source":["print(json.loads(json_result))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KM0uHZ88b9iw"},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMhmd+YNuUHy7JYkPSgn3+W","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.11"}},"nbformat":4,"nbformat_minor":0}
